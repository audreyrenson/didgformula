---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# didgformula

<!-- badges: start -->
<!-- badges: end -->

The R package `didgformula` implements inverse-probability weighted, iterated conditional g-computation, and doubly robust targeted maximum likelihood estimators for sustained intervention effects under parallel trends assumptions.

## Installation

Only the development version is available so far. You can install it from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("audreyrenson/didgformula")
```

## Examples

### Continuous outcomes

First we simulate some data under the stated assumptions:

```{r simulate-continuous}
library(didgformula)

set.seed(10)

time_periods = 5
N_obs        = 1e4
parameters   = generate_parameters(Tt=time_periods)
df           = generate_data(N=N_obs, Tt=time_periods, Beta=parameters, ylink = 'rnorm_identity')

head(df)
```

We can calculate the true parameters by generating a large number of potential outcomes under the same data-generating mechanism:

```{r}
df_po = generate_data(N=N_obs*10, Tt=time_periods, Beta=parameters, ylink='rnorm_identity', potential_outcomes = TRUE)

truth = colMeans(calc_ydiffs(df_po, Tt=time_periods)) #calc_ydiffs simply takes Y_t-Y_{t-1} for t=1,...,T
truth
```

We can estimate this using IPTW:

```{r}
estimates_iptw = iptw_pipeline(data = df, den_formula = '~L{t}', Tt=time_periods)
estimates_iptw
```
ICE:
```{r}
estimates_ice = ice_pipeline(data = df, inside_formula_t = '~L{t}', inside_formula_tmin1='~L{t-1}', outside_formula = '~L{k}', Tt=time_periods)
estimates_ice
```

